{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8207e9b9",
   "metadata": {},
   "source": [
    "# U-Net Workshop\n",
    "\n",
    "Here is an example U-Net implementation using minified data based upon creative commons dataset available at https://wiki.cancerimagingarchive.net/display/Public/HNSCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1538fbc",
   "metadata": {
    "id": "0ebfc39a"
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 Radiotherapy AI Pty Ltd\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc98afe",
   "metadata": {
    "id": "23a0eb9f"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "import shutil\n",
    "import urllib.request\n",
    "\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae24913",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "GRID_SIZE = 64\n",
    "\n",
    "COLOURS_AND_LABELS = [\n",
    "    (\"#ff7f0e\", \"left parotid\"),\n",
    "    (\"#2ca02c\", \"right parotid\"),\n",
    "    (\"#d62728\", \"external\"),\n",
    "]\n",
    "NUM_CONTOURS = len(COLOURS_AND_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad121a0",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9a4de0",
   "metadata": {
    "id": "138d8a13"
   },
   "outputs": [],
   "source": [
    "zip_url = \"https://github.com/RadiotherapyAI/unet-workshop/releases/download/mini-parotid/mini-parotid.zip\"\n",
    "zip_filepath = \"data.zip\"\n",
    "\n",
    "data_directory = pathlib.Path(\"data\")\n",
    "\n",
    "if not data_directory.exists():\n",
    "    urllib.request.urlretrieve(zip_url, zip_filepath)\n",
    "    shutil.unpack_archive(zip_filepath, data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fc61a6",
   "metadata": {
    "id": "8e492e5a"
   },
   "outputs": [],
   "source": [
    "dataset_types = [path.name for path in data_directory.glob(\"*\") if path.is_dir()]\n",
    "dataset_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02d5c7d",
   "metadata": {},
   "source": [
    "## Build the TensorFlow pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8786b10d",
   "metadata": {
    "id": "83dced47"
   },
   "outputs": [],
   "source": [
    "def get_path_pairs(dataset_type):\n",
    "    training_image_paths = list((data_directory / dataset_type).glob(\"*/*.image.png\"))\n",
    "    training_mask_paths = [\n",
    "        path.parent / f\"{path.name.split('.')[0]}.masks.png\"\n",
    "        for path in training_image_paths\n",
    "    ]\n",
    "\n",
    "    path_pairs = [\n",
    "        (str(image), str(mask))\n",
    "        for image, mask in zip(training_image_paths, training_mask_paths)\n",
    "    ]\n",
    "\n",
    "    return sorted(path_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418b6b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def load(path_pair):\n",
    "    image_path = path_pair[0]\n",
    "    masks_path = path_pair[1]\n",
    "    \n",
    "    image_raw = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_image(image_raw, channels=1, dtype=tf.uint8)\n",
    "\n",
    "    masks_raw = tf.io.read_file(masks_path)\n",
    "    masks = tf.io.decode_image(masks_raw, channels=3, dtype=tf.uint8)\n",
    "\n",
    "    return image / 255, masks / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873d4ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(dataset_type):\n",
    "    path_pairs = get_path_pairs(dataset_type)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(path_pairs)\n",
    "    dataset = dataset.shuffle(len(path_pairs), reshuffle_each_iteration=True)\n",
    "    dataset = dataset.map(load)\n",
    "\n",
    "    batched_dataset = dataset.batch(BATCH_SIZE)\n",
    "    batched_dataset = batched_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset, batched_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594a6a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset, training_batched_dataset = create_datasets(\"training\")\n",
    "validation_dataset, validation_batched_dataset = create_datasets(\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5194a4f9",
   "metadata": {
    "id": "b23e5637"
   },
   "outputs": [],
   "source": [
    "image, masks = iter(validation_dataset.take(1)).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac94d008",
   "metadata": {
    "id": "caeb3c4d"
   },
   "outputs": [],
   "source": [
    "plt.imshow(image[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e42267d",
   "metadata": {
    "id": "96e522f6"
   },
   "outputs": [],
   "source": [
    "plt.imshow(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bc4ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contours(ax, image, masks):\n",
    "    ax.imshow(image[:, :, 0], cmap=\"gray\")\n",
    "\n",
    "    for i, (colour, label) in enumerate(COLOURS_AND_LABELS):\n",
    "        c = ax.contour(masks[..., i], colors=[colour], levels=[0.5])\n",
    "        c.collections[0].set_label(label)\n",
    "\n",
    "    ax.axis(\"equal\")\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6af156",
   "metadata": {
    "id": "0c01233a"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "plot_contours(ax, image, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a5dde1",
   "metadata": {
    "id": "b8427c75"
   },
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def convolution(x, number_of_filters, kernel_size=3):\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        number_of_filters, kernel_size, padding=\"same\", kernel_initializer=\"he_normal\"\n",
    "    )(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_transpose(x, number_of_filters, kernel_size=3):\n",
    "    x = tf.keras.layers.Conv2DTranspose(\n",
    "        number_of_filters,\n",
    "        kernel_size,\n",
    "        strides=2,\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff71ef88",
   "metadata": {
    "id": "f23747a8"
   },
   "outputs": [],
   "source": [
    "def encode(\n",
    "    x,\n",
    "    number_of_filters,\n",
    "    number_of_convolutions=2,\n",
    "):\n",
    "    for _ in range(number_of_convolutions):\n",
    "        x = convolution(x, number_of_filters)\n",
    "        x = activation(x)\n",
    "    skip = x\n",
    "\n",
    "    x = tf.keras.layers.MaxPool2D()(x)\n",
    "    x = activation(x)\n",
    "\n",
    "    return x, skip\n",
    "\n",
    "\n",
    "def decode(\n",
    "    x,\n",
    "    skip,\n",
    "    number_of_filters,\n",
    "    number_of_convolutions=2,\n",
    "):\n",
    "    x = conv_transpose(x, number_of_filters)\n",
    "    x = activation(x)\n",
    "\n",
    "    x = tf.keras.layers.concatenate([skip, x], axis=3)\n",
    "\n",
    "    for _ in range(number_of_convolutions):\n",
    "        x = convolution(x, number_of_filters)\n",
    "        x = activation(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a81eb2",
   "metadata": {
    "id": "5256f817"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input((GRID_SIZE, GRID_SIZE, 1))\n",
    "\n",
    "x = inputs\n",
    "skips = []\n",
    "\n",
    "for number_of_filters in [32, 64, 128]:\n",
    "    x, skip = encode(x, number_of_filters)\n",
    "    skips.append(skip)\n",
    "\n",
    "skips.reverse()\n",
    "\n",
    "for number_of_filters, skip in zip([256, 128, 64], skips):\n",
    "    x = decode(x, skip, number_of_filters)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(\n",
    "    NUM_CONTOURS,\n",
    "    1,\n",
    "    activation=\"sigmoid\",\n",
    "    padding=\"same\",\n",
    "    kernel_initializer=\"he_normal\",\n",
    ")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30746c8a",
   "metadata": {
    "id": "38f49ce5"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f96b62f",
   "metadata": {
    "id": "dd577efa"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "        tf.keras.metrics.Precision(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a17da7f",
   "metadata": {
    "id": "6cac30f4"
   },
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88831e41",
   "metadata": {
    "id": "0a70a9aa"
   },
   "outputs": [],
   "source": [
    "pred_masks = model.predict(image[None, ...])[0, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8a2972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_prediction(image, masks, pred_masks):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6), ncols=2)\n",
    "    plot_contours(ax[0], image, masks)\n",
    "    plot_contours(ax[1], image, pred_masks)\n",
    "\n",
    "\n",
    "plot_with_prediction(image, masks, pred_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b031f5e",
   "metadata": {
    "id": "fad0871e"
   },
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        pred_masks = model.predict(image[None, ...])[0, ...]\n",
    "        plot_with_prediction(image, masks, pred_masks)\n",
    "\n",
    "        plt.show()\n",
    "        print(\"\\nSample Prediction after epoch {}\\n\".format(epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d26119f",
   "metadata": {
    "id": "2e201123"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    training_batched_dataset,\n",
    "    epochs=50,\n",
    "    validation_data=validation_batched_dataset,\n",
    "    callbacks=[DisplayCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65fd0c4",
   "metadata": {
    "id": "29c6c140"
   },
   "outputs": [],
   "source": [
    "plt.semilogy(history.history[\"loss\"], label=\"Training loss\")\n",
    "plt.semilogy(history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "U-Net Workshop",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
