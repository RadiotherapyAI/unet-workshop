{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "U-Net Workshop",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RadiotherapyAI/unet-workshop/blob/main/unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3db8ba2d"
      },
      "source": [
        "# U-Net Workshop\n",
        "\n",
        "Here is an example 2D U-Net implementation using minified data based upon creative commons dataset available at https://wiki.cancerimagingarchive.net/display/Public/HNSCC."
      ],
      "id": "3db8ba2d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a5f866a"
      },
      "source": [
        "# Copyright 2021 Radiotherapy AI Pty Ltd\n",
        "\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "\n",
        "#    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "id": "7a5f866a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21387b8b-76e4-4aa8-807b-2b5f81d5cdd9"
      },
      "source": [
        "## Overview\n",
        "\n",
        "* Library imports and namespaces\n",
        "* Utilising glob and pathlib\n",
        "* Plotting with matplotlib\n",
        "* Building a 2D UNet\n",
        "* Setting up a callback\n",
        "* Training the model and viewing the results\n",
        "\n",
        "### Some programming principles\n",
        "\n",
        "* Prototype to learn\n",
        "* Don't repeat yourself\n",
        "* Don't assume it, prove it\n",
        "* Design self-contained independent well-defined reusable components\n",
        "\n",
        "\n",
        "### Resources\n",
        "\n",
        "* [DRY -- \"Every piece of knowledge must have a single, unambiguous, authoritative representation within a system\"](http://media.pragprog.com/titles/tpp20/dry.pdf)\n",
        "* [NumPy for MATLAB users](https://numpy.org/doc/stable/user/numpy-for-matlab-users.html)\n",
        "* [PyTest primer](https://www.tutorialspoint.com/pytest/pytest_quick_guide.htm)"
      ],
      "id": "21387b8b-76e4-4aa8-807b-2b5f81d5cdd9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99ff2eeb-3bbd-4417-8417-d981d91e8e08"
      },
      "source": [
        "# First things first, describe the Google Colab interface\n",
        "# Make sure everyone can run a hello world.\n",
        "# Swap to CPU for now"
      ],
      "id": "99ff2eeb-3bbd-4417-8417-d981d91e8e08",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6020af38-2575-4d06-b5b8-e8edddbf20d3"
      },
      "source": [
        "## Library imports\n",
        "\n",
        "Here are a set of library imports, from both the standard library and some libraries downloadable from PyPI. These are imported within namespaces so as not to variable and function name conflicts."
      ],
      "id": "6020af38-2575-4d06-b5b8-e8edddbf20d3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "282b7a10-e11e-4e68-8a45-041b9505073e"
      },
      "source": [
        "import this"
      ],
      "id": "282b7a10-e11e-4e68-8a45-041b9505073e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0526338b"
      },
      "source": [
        "import pathlib\n",
        "import random\n",
        "import shutil\n",
        "import urllib.request\n",
        "\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "id": "0526338b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97448e73-cf46-4a98-bf63-84cbef42a751"
      },
      "source": [
        "# Show the effects of importing math with and without namespacing"
      ],
      "id": "97448e73-cf46-4a98-bf63-84cbef42a751",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39208213-7fcf-47c6-abb0-d6e64b58cd76"
      },
      "source": [
        "## Constants"
      ],
      "id": "39208213-7fcf-47c6-abb0-d6e64b58cd76"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04fee146"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "GRID_SIZE = 64\n",
        "\n",
        "DATASET_TYPES = {\"hold-out\", \"training\", \"validation\"}\n",
        "\n",
        "COLOURS_AND_LABELS = [\n",
        "    (\"#ff7f0e\", \"left parotid\"),\n",
        "    (\"#2ca02c\", \"right parotid\"),\n",
        "    (\"#d62728\", \"external\"),\n",
        "]\n",
        "# Single authoratative representation of knowledge\n",
        "NUM_CONTOURS = len(COLOURS_AND_LABELS)"
      ],
      "id": "04fee146",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c771439-771d-4048-80c2-0a87cef8ac4d"
      },
      "source": [
        "IMAGE_DIMENSIONS = (GRID_SIZE, GRID_SIZE, 1)\n",
        "MASK_DIMENSIONS = (GRID_SIZE, GRID_SIZE, NUM_CONTOURS)"
      ],
      "id": "1c771439-771d-4048-80c2-0a87cef8ac4d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37000c64-b506-48ad-aaf7-26986c5e7c6f"
      },
      "source": [
        "# Overview the set, list, and tuple types\n",
        "# The len function\n",
        "# Iteration over a list"
      ],
      "id": "37000c64-b506-48ad-aaf7-26986c5e7c6f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c80c0341-6437-4cd8-93ef-872d89929b40"
      },
      "source": [
        "EXPECTED_BATCH_IMAGE_DIMENSIONS = (\n",
        "    BATCH_SIZE,\n",
        "    *IMAGE_DIMENSIONS,\n",
        ")\n",
        "EXPECTED_BATCH_MASK_DIMENSIONS = (\n",
        "    BATCH_SIZE,\n",
        "    *MASK_DIMENSIONS,\n",
        ")"
      ],
      "id": "c80c0341-6437-4cd8-93ef-872d89929b40",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08bcfcec-cd36-4c18-aeef-d13ebe0f0f8c"
      },
      "source": [
        "# Demonstrate the effect of tuple unpacking"
      ],
      "id": "08bcfcec-cd36-4c18-aeef-d13ebe0f0f8c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f980fd7"
      },
      "source": [
        "## Download and investigate the data"
      ],
      "id": "8f980fd7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "041259e4-f7ad-4529-ab27-40130ffeb925"
      },
      "source": [
        "# Prototype data, prototype to learn\n",
        "\n",
        "zip_url = (\n",
        "    \"https://github.com/RadiotherapyAI/\"\n",
        "    \"unet-workshop/releases/download/\"\n",
        "    \"mini-parotid/mini-parotid.zip\"\n",
        ")\n",
        "zip_url"
      ],
      "id": "041259e4-f7ad-4529-ab27-40130ffeb925",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83c08ee3-4674-4489-8df9-997d7bab16ea"
      },
      "source": [
        "# Investigate the downloadable data within a filebrowser"
      ],
      "id": "83c08ee3-4674-4489-8df9-997d7bab16ea",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2007621"
      },
      "source": [
        "zip_filepath = \"data.zip\"\n",
        "\n",
        "data_directory = pathlib.Path(\"data\")\n",
        "\n",
        "if not data_directory.exists():\n",
        "    urllib.request.urlretrieve(zip_url, zip_filepath)\n",
        "    shutil.unpack_archive(zip_filepath, data_directory)"
      ],
      "id": "a2007621",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bd678e2-25aa-4114-ae30-e33340b0865c"
      },
      "source": [
        "# Investigate the downloaded data with pathlib and glob\n",
        "# Load an image with imageio and create a plot with\n",
        "# matplotlib's imshow\n",
        "\n",
        "## After demo -- BREAKOUT ROOMS -- gather feedback on tutorial's pace ##\n",
        "# -- GOAL: Have everyone able to plot\n",
        "#          the downloaded data, demoed first"
      ],
      "id": "1bd678e2-25aa-4114-ae30-e33340b0865c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5adde864"
      },
      "source": [
        "dataset_types_found = {\n",
        "    path.name\n",
        "    for path in data_directory.glob(\"*\")\n",
        "    if path.is_dir()\n",
        "}\n",
        "\n",
        "# Don't assume it, prove it\n",
        "assert dataset_types_found == DATASET_TYPES"
      ],
      "id": "5adde864",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71d8bf21"
      },
      "source": [
        "## Build the TensorFlow pipeline"
      ],
      "id": "71d8bf21"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3986095-ed69-4cbc-904d-2ef4a0dc513d"
      },
      "source": [
        "# Design re-usable components\n",
        "\n",
        "\n",
        "def get_image_paths(dataset_type):\n",
        "    image_paths = list(\n",
        "        (data_directory / dataset_type).glob(\n",
        "            \"*/*.image.png\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return image_paths"
      ],
      "id": "d3986095-ed69-4cbc-904d-2ef4a0dc513d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "500db62e-f1cb-4de5-9a19-4cbd17efb74d"
      },
      "source": [
        "# Explain the components of a function definition, inputs/outputs\n",
        "# Demo the usage of this function\n",
        "# Find the number of image paths for each dataset type"
      ],
      "id": "500db62e-f1cb-4de5-9a19-4cbd17efb74d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34b6e7df"
      },
      "source": [
        "def get_path_pairs(dataset_type):\n",
        "    image_paths = get_image_paths(dataset_type)\n",
        "    mask_paths = [\n",
        "        path.parent / f\"{path.name.split('.')[0]}.masks.png\"\n",
        "        for path in image_paths\n",
        "    ]\n",
        "\n",
        "    path_pairs = [\n",
        "        (str(image), str(mask))\n",
        "        for image, mask in zip(\n",
        "            image_paths,\n",
        "            mask_paths,\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    return sorted(path_pairs)"
      ],
      "id": "34b6e7df",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98c5a3e5"
      },
      "source": [
        "@tf.function\n",
        "def load(path_pair):\n",
        "    image_path = path_pair[0]\n",
        "    masks_path = path_pair[1]\n",
        "\n",
        "    image_raw = tf.io.read_file(image_path)\n",
        "    image = tf.io.decode_image(\n",
        "        image_raw, channels=1, dtype=tf.uint8\n",
        "    )\n",
        "\n",
        "    masks_raw = tf.io.read_file(masks_path)\n",
        "    masks = tf.io.decode_image(\n",
        "        masks_raw, channels=NUM_CONTOURS, dtype=tf.uint8\n",
        "    )\n",
        "\n",
        "    return image / 255, masks / 255"
      ],
      "id": "98c5a3e5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf0ad1fb"
      },
      "source": [
        "def create_datasets(dataset_type):\n",
        "    path_pairs = get_path_pairs(dataset_type)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(path_pairs)\n",
        "    dataset = dataset.shuffle(\n",
        "        len(path_pairs),\n",
        "        reshuffle_each_iteration=True,\n",
        "    )\n",
        "    dataset = dataset.map(load)\n",
        "\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset"
      ],
      "id": "cf0ad1fb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "230f761d"
      },
      "source": [
        "datasets = {}\n",
        "\n",
        "for dataset_type in DATASET_TYPES:\n",
        "    datasets[dataset_type] = create_datasets(dataset_type)\n",
        "\n",
        "datasets"
      ],
      "id": "230f761d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e8a2b71-f179-4470-8221-ca7403702825"
      },
      "source": [
        "# A description on dictionaries, and how they can be used\n",
        "# to apply a single task to many variables"
      ],
      "id": "5e8a2b71-f179-4470-8221-ca7403702825",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73118e6e-b902-4530-b753-13a1bf3d4844"
      },
      "source": [
        "## BREAKOUT ROOMS ##\n",
        "# -- Goal: Use a for loop to build a dictionary\n",
        "#          containing the length of each dataset"
      ],
      "id": "73118e6e-b902-4530-b753-13a1bf3d4844",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "192cd10b-e212-4e7f-81c8-27a289fc3d39"
      },
      "source": [
        "# Don't assume it, prove it\n",
        "# The code below when uncommented raises an assertion error. Why?\n",
        "\n",
        "# for batched_images, batched_masks in datasets[\"training\"]:\n",
        "#     # Include this after seeing the assertion error\n",
        "#     # print(batched_images.shape)\n",
        "#     assert (\n",
        "#         batched_images.shape\n",
        "#         == EXPECTED_BATCH_IMAGE_DIMENSIONS\n",
        "#     )\n",
        "#     assert (\n",
        "#         batched_masks.shape\n",
        "#         == EXPECTED_BATCH_MASK_DIMENSIONS\n",
        "#     )"
      ],
      "id": "192cd10b-e212-4e7f-81c8-27a289fc3d39",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60f5b9b9-fdb1-44c8-9229-6d506a9c1a3c"
      },
      "source": [
        "# Why did this assertion fail?"
      ],
      "id": "60f5b9b9-fdb1-44c8-9229-6d506a9c1a3c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e94fe68-bdce-41d5-81ef-f81fc6fdea08"
      },
      "source": [
        "def dataset_dimensions_check(dataset_type):\n",
        "    number_of_images = len(get_image_paths(dataset_type))\n",
        "    assert number_of_images > 0\n",
        "\n",
        "    dataset = create_datasets(dataset_type)\n",
        "\n",
        "    image_shapes = []\n",
        "    mask_shapes = []\n",
        "\n",
        "    for batched_images, batched_masks in dataset:\n",
        "        image_shapes.append(batched_images.shape)\n",
        "        mask_shapes.append(batched_masks.shape)\n",
        "\n",
        "    for image_shape, mask_shape in zip(\n",
        "        image_shapes[:-1], mask_shapes[:-1]\n",
        "    ):\n",
        "        assert (\n",
        "            image_shape == EXPECTED_BATCH_IMAGE_DIMENSIONS\n",
        "        )\n",
        "        assert mask_shape == EXPECTED_BATCH_MASK_DIMENSIONS\n",
        "\n",
        "    remaining_batch_size = number_of_images % BATCH_SIZE\n",
        "\n",
        "    assert image_shapes[-1] == (\n",
        "        remaining_batch_size,\n",
        "        *IMAGE_DIMENSIONS,\n",
        "    )\n",
        "    assert mask_shapes[-1] == (\n",
        "        remaining_batch_size,\n",
        "        *MASK_DIMENSIONS,\n",
        "    )\n",
        "\n",
        "\n",
        "# Can move a function like this into its own Python file\n",
        "# named `test_dataset.py` to allow it to be picked up by\n",
        "# the automated testing framework `PyTest`.\n",
        "# https://www.tutorialspoint.com/pytest/pytest_quick_guide.htm\n",
        "\n",
        "\n",
        "def test_dataset_dimensions():\n",
        "    for dataset_type in DATASET_TYPES:\n",
        "        print(dataset_type)\n",
        "        dataset_dimensions_check(dataset_type)\n",
        "\n",
        "\n",
        "# Need to 'test your tests'\n",
        "test_dataset_dimensions()\n",
        "\n",
        "# Verify that this test appropriately fails if items above are changed\n",
        "\n",
        "## BREAKOUT ROOMS ##\n",
        "# -- Goal: Everyone able to break and then repair the above test"
      ],
      "id": "9e94fe68-bdce-41d5-81ef-f81fc6fdea08",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "038e5131-7eba-441b-93e0-c3129b5f55b3"
      },
      "source": [
        "## Investigate the created pipeline"
      ],
      "id": "038e5131-7eba-441b-93e0-c3129b5f55b3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b02fb59c"
      },
      "source": [
        "batch_validation_images, batch_validation_masks = iter(\n",
        "    datasets[\"validation\"].take(1)\n",
        ").next()"
      ],
      "id": "b02fb59c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e01d909-eda6-4467-aae8-8dc62b7d2d3f"
      },
      "source": [
        "# Investigate the shapes of the batched images and masks"
      ],
      "id": "3e01d909-eda6-4467-aae8-8dc62b7d2d3f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42b175dc-ca87-47b5-8165-d3fbfd8fc2cc"
      },
      "source": [
        "image = batch_validation_images[0, ...]\n",
        "masks = batch_validation_masks[0, ...]"
      ],
      "id": "42b175dc-ca87-47b5-8165-d3fbfd8fc2cc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "124de75b-ab1c-4e7c-85a4-a75e5e46f5ca"
      },
      "source": [
        "# Investigate the shapes of the newly indexed objects"
      ],
      "id": "124de75b-ab1c-4e7c-85a4-a75e5e46f5ca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4bb9d87-ca1f-4e0a-8465-5460ef4629e1"
      },
      "source": [
        "# Use imshow to view these images and masks"
      ],
      "id": "c4bb9d87-ca1f-4e0a-8465-5460ef4629e1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0423e442-81fd-43cf-87a0-b40a1f604028"
      },
      "source": [
        "## Create a useful representation of the data"
      ],
      "id": "0423e442-81fd-43cf-87a0-b40a1f604028"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8f556da"
      },
      "source": [
        "def plot_contours(ax, image, masks):\n",
        "    ax.imshow(image[:, :, 0], cmap=\"gray\")\n",
        "\n",
        "    for i, (colour, label) in enumerate(COLOURS_AND_LABELS):\n",
        "        if np.all(masks[..., i] < 0.5) or np.all(\n",
        "            masks[..., i] > 0.5\n",
        "        ):\n",
        "            continue\n",
        "\n",
        "        c = ax.contour(\n",
        "            masks[..., i],\n",
        "            colors=[colour],\n",
        "            levels=[0.5],\n",
        "        )\n",
        "        c.collections[0].set_label(label)\n",
        "\n",
        "    ax.axis(\"equal\")\n",
        "    ax.legend()"
      ],
      "id": "c8f556da",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "226551ec"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "# Use the plot_contours function\n",
        "\n",
        "## BREAKOUT ROOMS ##\n",
        "# -- Goal: Everyone able to investigate the validation images and masks"
      ],
      "id": "226551ec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bc0b6b0-bd49-4009-8b02-cd9544ece837"
      },
      "source": [
        "## Building the 2D U-Net model\n",
        "\n",
        "In this section we will create a Tensorflow Keras 2D UNet model utilising a set of pre-built functions. An example UNet diagram is given below for aiding explanation:\n",
        "\n",
        "![](https://github.com/RadiotherapyAI/unet-workshop/blob/019f25013030e51b83e2370b347bf5933aebc37c/images/unet.png?raw=1)"
      ],
      "id": "5bc0b6b0-bd49-4009-8b02-cd9544ece837"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b8610fb"
      },
      "source": [
        "def activation(x):\n",
        "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def convolution(x, number_of_filters, kernel_size=3):\n",
        "    x = tf.keras.layers.Conv2D(\n",
        "        number_of_filters,\n",
        "        kernel_size,\n",
        "        padding=\"same\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "    )(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_transpose(x, number_of_filters, kernel_size=3):\n",
        "    x = tf.keras.layers.Conv2DTranspose(\n",
        "        number_of_filters,\n",
        "        kernel_size,\n",
        "        strides=2,\n",
        "        padding=\"same\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "    )(x)\n",
        "\n",
        "    return x"
      ],
      "id": "1b8610fb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d16a564-6c12-4a39-a6eb-0ff0405d0f96"
      },
      "source": [
        "# Highlight where the activation, convolution, and conv_transpose occurs in the UNet diagram"
      ],
      "id": "9d16a564-6c12-4a39-a6eb-0ff0405d0f96",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1543ea7a"
      },
      "source": [
        "def encode(\n",
        "    x,\n",
        "    number_of_filters,\n",
        "    number_of_convolutions=2,\n",
        "):\n",
        "    \"\"\"An encoding layer within a 2D UNet\"\"\"\n",
        "    for _ in range(number_of_convolutions):\n",
        "        x = convolution(x, number_of_filters)\n",
        "        x = activation(x)\n",
        "    skip = x\n",
        "\n",
        "    x = tf.keras.layers.MaxPool2D()(x)\n",
        "    x = activation(x)\n",
        "\n",
        "    return x, skip\n",
        "\n",
        "\n",
        "def decode(\n",
        "    x,\n",
        "    skip,\n",
        "    number_of_filters,\n",
        "    number_of_convolutions=2,\n",
        "):\n",
        "    \"\"\"A decoding layer within a 2D UNet\"\"\"\n",
        "    x = conv_transpose(x, number_of_filters)\n",
        "    x = activation(x)\n",
        "\n",
        "    x = tf.keras.layers.concatenate([skip, x], axis=-1)\n",
        "\n",
        "    for _ in range(number_of_convolutions):\n",
        "        x = convolution(x, number_of_filters)\n",
        "        x = activation(x)\n",
        "\n",
        "    return x"
      ],
      "id": "1543ea7a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65f54b92-354e-4b3a-92c6-9bd5c8a28c4c"
      },
      "source": [
        "# Highlight the encode and decode sections of the UNet"
      ],
      "id": "65f54b92-354e-4b3a-92c6-9bd5c8a28c4c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25324da3-1f3d-4f2a-8611-42ac62c7ef25"
      },
      "source": [
        "def get_unet_filter_counts(grid_size):\n",
        "    \"\"\"Return a reasonable set of convolution filter sizes for a UNet\"\"\"\n",
        "    network_depth = int(np.log2(grid_size / 8))\n",
        "    encoding_filter_counts = 2 ** (\n",
        "        np.array(range(network_depth)) + 5\n",
        "    )\n",
        "    decoding_filter_counts = (\n",
        "        2 ** (np.array(range(network_depth)) + 6)[::-1]\n",
        "    )\n",
        "\n",
        "    return (\n",
        "        encoding_filter_counts,\n",
        "        decoding_filter_counts,\n",
        "    )"
      ],
      "id": "25324da3-1f3d-4f2a-8611-42ac62c7ef25",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a7cdad4-846f-4b90-bde9-8a54eeb2b101"
      },
      "source": [
        "# Show the effect of a range of different grid_sizes"
      ],
      "id": "3a7cdad4-846f-4b90-bde9-8a54eeb2b101",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e35d96f-4a92-4b79-bf6e-f9e583d2ca8a"
      },
      "source": [
        "def unet(grid_size, num_contours):\n",
        "    \"\"\"Create a bare-bones 2D UNet\"\"\"\n",
        "    inputs = tf.keras.layers.Input(\n",
        "        (grid_size, grid_size, 1)\n",
        "    )\n",
        "\n",
        "    (\n",
        "        encoding_filter_counts,\n",
        "        decoding_filter_counts,\n",
        "    ) = get_unet_filter_counts(grid_size)\n",
        "\n",
        "    x = inputs\n",
        "    skips = []\n",
        "\n",
        "    for number_of_filters in encoding_filter_counts:\n",
        "        x, skip = encode(x, number_of_filters)\n",
        "        skips.append(skip)\n",
        "\n",
        "    skips.reverse()\n",
        "\n",
        "    for number_of_filters, skip in zip(\n",
        "        decoding_filter_counts, skips\n",
        "    ):\n",
        "        x = decode(x, skip, number_of_filters)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(\n",
        "        num_contours,\n",
        "        1,\n",
        "        activation=\"sigmoid\",\n",
        "        padding=\"same\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "    )(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=x)\n",
        "\n",
        "    return model"
      ],
      "id": "6e35d96f-4a92-4b79-bf6e-f9e583d2ca8a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3a12d20"
      },
      "source": [
        "model = unet(GRID_SIZE, NUM_CONTOURS)\n",
        "model.summary()"
      ],
      "id": "b3a12d20",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "529c6094"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics=[\n",
        "        tf.keras.metrics.BinaryAccuracy(),\n",
        "        tf.keras.metrics.Recall(),\n",
        "        tf.keras.metrics.Precision(),\n",
        "    ],\n",
        ")"
      ],
      "id": "529c6094",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae86d2cf-6591-4159-8eca-956fa428cc6b"
      },
      "source": [
        "# Utilise the untrained model to create a prediction"
      ],
      "id": "ae86d2cf-6591-4159-8eca-956fa428cc6b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3547689-a74c-4c17-ba0f-87f2067032c4"
      },
      "source": [
        "# Use the previously defined plot_contour to show this prediction"
      ],
      "id": "d3547689-a74c-4c17-ba0f-87f2067032c4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09d8f781-7b72-41e2-bd92-46bc3da956a1"
      },
      "source": [
        "def plot_with_prediction(image, masks, pred_masks):\n",
        "    fig, ax = plt.subplots(figsize=(12, 6), ncols=2)\n",
        "    plot_contours(ax[0], image, masks)\n",
        "    plot_contours(ax[1], image, pred_masks)"
      ],
      "id": "09d8f781-7b72-41e2-bd92-46bc3da956a1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3acd3766-ae77-44f8-91fd-1971fe06bc27"
      },
      "source": [
        "# Use this new function, plot_with_prediction, to see a comparison"
      ],
      "id": "3acd3766-ae77-44f8-91fd-1971fe06bc27",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e787dd5-c6f5-4d15-9230-36a5f188cea1"
      },
      "source": [
        "class DisplayCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pred_masks = model.predict(image[None, ...])[0, ...]\n",
        "        plot_with_prediction(image, masks, pred_masks)\n",
        "\n",
        "        plt.show()\n",
        "        print(\n",
        "            \"\\nSample Prediction after\"\n",
        "            \" epoch {}\\n\".format(epoch + 1)\n",
        "        )"
      ],
      "id": "4e787dd5-c6f5-4d15-9230-36a5f188cea1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0234e5f1-993f-4d9a-9505-d091c9512a44"
      },
      "source": [
        "# Describe classes\n",
        "# Instantiate this callback class and\n",
        "# call the on_epoch_end method to see what it does"
      ],
      "id": "0234e5f1-993f-4d9a-9505-d091c9512a44",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e482d6b8-81b0-4b26-8f38-43a75bbfc199"
      },
      "source": [
        "## Training"
      ],
      "id": "e482d6b8-81b0-4b26-8f38-43a75bbfc199"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fcf2447-fcc9-4011-bffd-e96eb3e8b178"
      },
      "source": [
        "# Swap to GPU runtime\n",
        "# Run all cells"
      ],
      "id": "7fcf2447-fcc9-4011-bffd-e96eb3e8b178",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b8d9a31"
      },
      "source": [
        "history = model.fit(\n",
        "    datasets[\"training\"],\n",
        "    epochs=50,\n",
        "    validation_data=datasets[\"validation\"],\n",
        "    callbacks=[DisplayCallback()],\n",
        ")"
      ],
      "id": "9b8d9a31",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b855ca3-7347-48ff-8110-b04eb075daa2"
      },
      "source": [
        "# Compare the training results. Sometimes it won't converge.\n",
        "# Can re-initialise the model and re-train in that case.\n",
        "\n",
        "## BREAKOUT ROOMS ##\n",
        "# -- Goal: Catch everyone up, and have everyone be able to train a UNet"
      ],
      "id": "8b855ca3-7347-48ff-8110-b04eb075daa2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "568a167b"
      },
      "source": [
        "plt.semilogy(history.history[\"loss\"], label=\"Training loss\")\n",
        "plt.semilogy(\n",
        "    history.history[\"val_loss\"],\n",
        "    label=\"Validation loss\",\n",
        ")\n",
        "plt.legend()"
      ],
      "id": "568a167b",
      "execution_count": null,
      "outputs": []
    }
  ]
}