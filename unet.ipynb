{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3db8ba2d",
   "metadata": {},
   "source": [
    "# U-Net Workshop\n",
    "\n",
    "Here is an example 2D U-Net implementation using minified data based upon creative commons dataset available at https://wiki.cancerimagingarchive.net/display/Public/HNSCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5f866a",
   "metadata": {
    "id": "0ebfc39a"
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 Radiotherapy AI Pty Ltd\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21387b8b-76e4-4aa8-807b-2b5f81d5cdd9",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "* Library imports and namespaces\n",
    "* Utilising glob and pathlib\n",
    "* Plotting with matplotlib\n",
    "* Building a 2D UNet\n",
    "* Setting up a callback\n",
    "* Training the model and viewing the results\n",
    "\n",
    "### Some programming principles\n",
    "\n",
    "* Prototype to learn\n",
    "* Don't repeat yourself\n",
    "* Don't assume it, prove it\n",
    "* Design self-contained independent well-defined reusable components\n",
    "\n",
    "\n",
    "### Resources\n",
    "\n",
    "* [DRY -- *\"Every piece of knowledge must have a single, unambiguous, authoritative representation within a system\"*](http://media.pragprog.com/titles/tpp20/dry.pdf)\n",
    "* [NumPy for MATLAB users](https://numpy.org/doc/stable/user/numpy-for-matlab-users.html)\n",
    "* [PyTest primer](https://www.tutorialspoint.com/pytest/pytest_quick_guide.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff2eeb-3bbd-4417-8417-d981d91e8e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First things first, describe the Google Colab interface\n",
    "# Make sure everyone can run a hello world.\n",
    "# Swap to CPU for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6020af38-2575-4d06-b5b8-e8edddbf20d3",
   "metadata": {},
   "source": [
    "## Library imports\n",
    "\n",
    "Here are a set of library imports, from both the standard library and some libraries downloadable from PyPI. These are imported within namespaces so as not to variable and function name conflicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282b7a10-e11e-4e68-8a45-041b9505073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0526338b",
   "metadata": {
    "id": "23a0eb9f"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "import shutil\n",
    "import urllib.request\n",
    "\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97448e73-cf46-4a98-bf63-84cbef42a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the effects of importing math with and without namespacing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39208213-7fcf-47c6-abb0-d6e64b58cd76",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fee146",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "GRID_SIZE = 64\n",
    "\n",
    "DATASET_TYPES = {\"hold-out\", \"training\", \"validation\"}\n",
    "\n",
    "COLOURS_AND_LABELS = [\n",
    "    (\"#ff7f0e\", \"left parotid\"),\n",
    "    (\"#2ca02c\", \"right parotid\"),\n",
    "    (\"#d62728\", \"external\"),\n",
    "]\n",
    "# Single authoratative representation of knowledge\n",
    "NUM_CONTOURS = len(COLOURS_AND_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c771439-771d-4048-80c2-0a87cef8ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIMENSIONS = (GRID_SIZE, GRID_SIZE, 1)\n",
    "MASK_DIMENSIONS = (GRID_SIZE, GRID_SIZE, NUM_CONTOURS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37000c64-b506-48ad-aaf7-26986c5e7c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview the set, list, and tuple types\n",
    "# The len function\n",
    "# Iteration over a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c0341-6437-4cd8-93ef-872d89929b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPECTED_BATCH_IMAGE_DIMENSIONS = (\n",
    "    BATCH_SIZE,\n",
    "    *IMAGE_DIMENSIONS,\n",
    ")\n",
    "EXPECTED_BATCH_MASK_DIMENSIONS = (\n",
    "    BATCH_SIZE,\n",
    "    *MASK_DIMENSIONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bcfcec-cd36-4c18-aeef-d13ebe0f0f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the effect of tuple unpacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f980fd7",
   "metadata": {},
   "source": [
    "## Download and investigate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041259e4-f7ad-4529-ab27-40130ffeb925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prototype data, prototype to learn\n",
    "\n",
    "zip_url = (\n",
    "    \"https://github.com/RadiotherapyAI/\"\n",
    "    \"unet-workshop/releases/download/\"\n",
    "    \"mini-parotid/mini-parotid.zip\"\n",
    ")\n",
    "zip_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c08ee3-4674-4489-8df9-997d7bab16ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the downloadable data within a filebrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2007621",
   "metadata": {
    "id": "138d8a13"
   },
   "outputs": [],
   "source": [
    "zip_filepath = \"data.zip\"\n",
    "\n",
    "data_directory = pathlib.Path(\"data\")\n",
    "\n",
    "if not data_directory.exists():\n",
    "    urllib.request.urlretrieve(zip_url, zip_filepath)\n",
    "    shutil.unpack_archive(zip_filepath, data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd678e2-25aa-4114-ae30-e33340b0865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the downloaded data with pathlib and glob\n",
    "# Load an image with imageio and create a plot with\n",
    "# matplotlib's imshow\n",
    "\n",
    "## After demo -- BREAKOUT ROOMS -- gather feedback on tutorial's pace ##\n",
    "# -- GOAL: Have everyone able to plot\n",
    "#          the downloaded data, demoed first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adde864",
   "metadata": {
    "id": "8e492e5a"
   },
   "outputs": [],
   "source": [
    "dataset_types_found = {\n",
    "    path.name\n",
    "    for path in data_directory.glob(\"*\")\n",
    "    if path.is_dir()\n",
    "}\n",
    "\n",
    "# Don't assume it, prove it\n",
    "assert dataset_types_found == DATASET_TYPES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d8bf21",
   "metadata": {},
   "source": [
    "## Build the TensorFlow pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3986095-ed69-4cbc-904d-2ef4a0dc513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design re-usable components\n",
    "\n",
    "\n",
    "def get_image_paths(dataset_type):\n",
    "    image_paths = list(\n",
    "        (data_directory / dataset_type).glob(\n",
    "            \"*/*.image.png\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500db62e-f1cb-4de5-9a19-4cbd17efb74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain the components of a function definition, inputs/outputs\n",
    "# Demo the usage of this function\n",
    "# Find the number of image paths for each dataset type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b6e7df",
   "metadata": {
    "id": "83dced47"
   },
   "outputs": [],
   "source": [
    "def get_path_pairs(dataset_type):\n",
    "    image_paths = get_image_paths(dataset_type)\n",
    "    mask_paths = [\n",
    "        path.parent / f\"{path.name.split('.')[0]}.masks.png\"\n",
    "        for path in image_paths\n",
    "    ]\n",
    "\n",
    "    path_pairs = [\n",
    "        (str(image), str(mask))\n",
    "        for image, mask in zip(\n",
    "            image_paths,\n",
    "            mask_paths,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return sorted(path_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c5a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def load(path_pair):\n",
    "    image_path = path_pair[0]\n",
    "    masks_path = path_pair[1]\n",
    "\n",
    "    image_raw = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_image(\n",
    "        image_raw, channels=1, dtype=tf.uint8\n",
    "    )\n",
    "\n",
    "    masks_raw = tf.io.read_file(masks_path)\n",
    "    masks = tf.io.decode_image(\n",
    "        masks_raw, channels=NUM_CONTOURS, dtype=tf.uint8\n",
    "    )\n",
    "\n",
    "    return image / 255, masks / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0ad1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(dataset_type):\n",
    "    path_pairs = get_path_pairs(dataset_type)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(path_pairs)\n",
    "    dataset = dataset.shuffle(\n",
    "        len(path_pairs),\n",
    "        reshuffle_each_iteration=True,\n",
    "    )\n",
    "    dataset = dataset.map(load)\n",
    "\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230f761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "\n",
    "for dataset_type in DATASET_TYPES:\n",
    "    datasets[dataset_type] = create_datasets(dataset_type)\n",
    "\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8a2b71-f179-4470-8221-ca7403702825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A description on dictionaries, and how they can be used\n",
    "# to apply a single task to many variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73118e6e-b902-4530-b753-13a1bf3d4844",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BREAKOUT ROOMS ##\n",
    "# -- Goal: Use a for loop to build a dictionary\n",
    "#          containing the length of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192cd10b-e212-4e7f-81c8-27a289fc3d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't assume it, prove it\n",
    "\n",
    "for batched_images, batched_masks in datasets[\"training\"]:\n",
    "    # Include this after seeing the assertion error\n",
    "    # print(batched_images.shape)\n",
    "    assert (\n",
    "        batched_images.shape\n",
    "        == EXPECTED_BATCH_IMAGE_DIMENSIONS\n",
    "    )\n",
    "    assert (\n",
    "        batched_masks.shape\n",
    "        == EXPECTED_BATCH_MASK_DIMENSIONS\n",
    "    )\n",
    "\n",
    "# After used comment out this whole cell with\n",
    "# `Ctrl + /` so that \"Run All Cells\" doesn't\n",
    "# error out anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f5b9b9-fdb1-44c8-9229-6d506a9c1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why did this assertion fail?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e94fe68-bdce-41d5-81ef-f81fc6fdea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_dimensions_check(dataset_type):\n",
    "    number_of_images = len(get_image_paths(dataset_type))\n",
    "    assert number_of_images > 0\n",
    "\n",
    "    dataset = create_datasets(dataset_type)\n",
    "\n",
    "    image_shapes = []\n",
    "    mask_shapes = []\n",
    "\n",
    "    for batched_images, batched_masks in dataset:\n",
    "        image_shapes.append(batched_images.shape)\n",
    "        mask_shapes.append(batched_masks.shape)\n",
    "\n",
    "    for image_shape, mask_shape in zip(\n",
    "        image_shapes[:-1], mask_shapes[:-1]\n",
    "    ):\n",
    "        assert (\n",
    "            image_shape == EXPECTED_BATCH_IMAGE_DIMENSIONS\n",
    "        )\n",
    "        assert mask_shape == EXPECTED_BATCH_MASK_DIMENSIONS\n",
    "\n",
    "    remaining_batch_size = number_of_images % BATCH_SIZE\n",
    "\n",
    "    assert image_shapes[-1] == (\n",
    "        remaining_batch_size,\n",
    "        *IMAGE_DIMENSIONS,\n",
    "    )\n",
    "    assert mask_shapes[-1] == (\n",
    "        remaining_batch_size,\n",
    "        *MASK_DIMENSIONS,\n",
    "    )\n",
    "\n",
    "\n",
    "# Can move a function like this into its own Python file\n",
    "# named `test_dataset.py` to allow it to be picked up by\n",
    "# the automated testing framework `PyTest`.\n",
    "# https://www.tutorialspoint.com/pytest/pytest_quick_guide.htm\n",
    "\n",
    "\n",
    "def test_dataset_dimensions():\n",
    "    for dataset_type in DATASET_TYPES:\n",
    "        print(dataset_type)\n",
    "        dataset_dimensions_check(dataset_type)\n",
    "\n",
    "\n",
    "# Need to 'test your tests'\n",
    "test_dataset_dimensions()\n",
    "\n",
    "# Verify that this test appropriately fails if items above are changed\n",
    "\n",
    "## BREAKOUT ROOMS ##\n",
    "# -- Goal: Everyone able to break and then repair the above test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038e5131-7eba-441b-93e0-c3129b5f55b3",
   "metadata": {},
   "source": [
    "## Investigate the created pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02fb59c",
   "metadata": {
    "id": "b23e5637"
   },
   "outputs": [],
   "source": [
    "batch_validation_images, batch_validation_masks = iter(\n",
    "    datasets[\"validation\"].take(1)\n",
    ").next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e01d909-eda6-4467-aae8-8dc62b7d2d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the shapes of the batched images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b175dc-ca87-47b5-8165-d3fbfd8fc2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = batch_validation_images[0, ...]\n",
    "masks = batch_validation_masks[0, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124de75b-ab1c-4e7c-85a4-a75e5e46f5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the shapes of the newly indexed objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bb9d87-ca1f-4e0a-8465-5460ef4629e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use imshow to view these images and masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0423e442-81fd-43cf-87a0-b40a1f604028",
   "metadata": {},
   "source": [
    "## Create a useful representation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f556da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contours(ax, image, masks):\n",
    "    ax.imshow(image[:, :, 0], cmap=\"gray\")\n",
    "\n",
    "    for i, (colour, label) in enumerate(COLOURS_AND_LABELS):\n",
    "        if np.all(masks[..., i] < 0.5) or np.all(\n",
    "            masks[..., i] > 0.5\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        c = ax.contour(\n",
    "            masks[..., i],\n",
    "            colors=[colour],\n",
    "            levels=[0.5],\n",
    "        )\n",
    "        c.collections[0].set_label(label)\n",
    "\n",
    "    ax.axis(\"equal\")\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226551ec",
   "metadata": {
    "id": "0c01233a"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "# Use the plot_contours function\n",
    "\n",
    "## BREAKOUT ROOMS ##\n",
    "# -- Goal: Everyone able to investigate the validation images and masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc0b6b0-bd49-4009-8b02-cd9544ece837",
   "metadata": {},
   "source": [
    "## Building the 2D U-Net model\n",
    "\n",
    "In this section we will create a Tensorflow Keras 2D UNet model utilising a set of pre-built functions. An example UNet diagram is given below for aiding explanation:\n",
    "\n",
    "![](./images/unet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8610fb",
   "metadata": {
    "id": "b8427c75"
   },
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def convolution(x, number_of_filters, kernel_size=3):\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        number_of_filters,\n",
    "        kernel_size,\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_transpose(x, number_of_filters, kernel_size=3):\n",
    "    x = tf.keras.layers.Conv2DTranspose(\n",
    "        number_of_filters,\n",
    "        kernel_size,\n",
    "        strides=2,\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d16a564-6c12-4a39-a6eb-0ff0405d0f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlight where the activation, convolution, and conv_transpose occurs in the UNet diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1543ea7a",
   "metadata": {
    "id": "f23747a8"
   },
   "outputs": [],
   "source": [
    "def encode(\n",
    "    x,\n",
    "    number_of_filters,\n",
    "    number_of_convolutions=2,\n",
    "):\n",
    "    \"\"\"An encoding layer within a 2D UNet\"\"\"\n",
    "    for _ in range(number_of_convolutions):\n",
    "        x = convolution(x, number_of_filters)\n",
    "        x = activation(x)\n",
    "    skip = x\n",
    "\n",
    "    x = tf.keras.layers.MaxPool2D()(x)\n",
    "    x = activation(x)\n",
    "\n",
    "    return x, skip\n",
    "\n",
    "\n",
    "def decode(\n",
    "    x,\n",
    "    skip,\n",
    "    number_of_filters,\n",
    "    number_of_convolutions=2,\n",
    "):\n",
    "    \"\"\"A decoding layer within a 2D UNet\"\"\"\n",
    "    x = conv_transpose(x, number_of_filters)\n",
    "    x = activation(x)\n",
    "\n",
    "    x = tf.keras.layers.concatenate([skip, x], axis=-1)\n",
    "\n",
    "    for _ in range(number_of_convolutions):\n",
    "        x = convolution(x, number_of_filters)\n",
    "        x = activation(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f54b92-354e-4b3a-92c6-9bd5c8a28c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlight the encode and decode sections of the UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25324da3-1f3d-4f2a-8611-42ac62c7ef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet_filter_counts(grid_size):\n",
    "    \"\"\"Return a reasonable set of convolution filter sizes for a UNet\"\"\"\n",
    "    network_depth = int(np.log2(grid_size / 8))\n",
    "    encoding_filter_counts = 2 ** (\n",
    "        np.array(range(network_depth)) + 5\n",
    "    )\n",
    "    decoding_filter_counts = (\n",
    "        2 ** (np.array(range(network_depth)) + 6)[::-1]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        encoding_filter_counts,\n",
    "        decoding_filter_counts,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7cdad4-846f-4b90-bde9-8a54eeb2b101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the effect of a range of different grid_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e35d96f-4a92-4b79-bf6e-f9e583d2ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(grid_size, num_contours):\n",
    "    \"\"\"Create a bare-bones 2D UNet\"\"\"\n",
    "    inputs = tf.keras.layers.Input(\n",
    "        (grid_size, grid_size, 1)\n",
    "    )\n",
    "\n",
    "    (\n",
    "        encoding_filter_counts,\n",
    "        decoding_filter_counts,\n",
    "    ) = get_unet_filter_counts(grid_size)\n",
    "\n",
    "    x = inputs\n",
    "    skips = []\n",
    "\n",
    "    for number_of_filters in encoding_filter_counts:\n",
    "        x, skip = encode(x, number_of_filters)\n",
    "        skips.append(skip)\n",
    "\n",
    "    skips.reverse()\n",
    "\n",
    "    for number_of_filters, skip in zip(\n",
    "        decoding_filter_counts, skips\n",
    "    ):\n",
    "        x = decode(x, skip, number_of_filters)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        num_contours,\n",
    "        1,\n",
    "        activation=\"sigmoid\",\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a12d20",
   "metadata": {
    "id": "5256f817"
   },
   "outputs": [],
   "source": [
    "model = unet(GRID_SIZE, NUM_CONTOURS)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529c6094",
   "metadata": {
    "id": "dd577efa"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "        tf.keras.metrics.Precision(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae86d2cf-6591-4159-8eca-956fa428cc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilise the untrained model to create a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3547689-a74c-4c17-ba0f-87f2067032c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the previously defined plot_contour to show this prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d8f781-7b72-41e2-bd92-46bc3da956a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_prediction(image, masks, pred_masks):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6), ncols=2)\n",
    "    plot_contours(ax[0], image, masks)\n",
    "    plot_contours(ax[1], image, pred_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd3766-ae77-44f8-91fd-1971fe06bc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this new function, plot_with_prediction, to see a comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e787dd5-c6f5-4d15-9230-36a5f188cea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        pred_masks = model.predict(image[None, ...])[0, ...]\n",
    "        plot_with_prediction(image, masks, pred_masks)\n",
    "\n",
    "        plt.show()\n",
    "        print(\n",
    "            \"\\nSample Prediction after\"\n",
    "            \" epoch {}\\n\".format(epoch + 1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0234e5f1-993f-4d9a-9505-d091c9512a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe classes\n",
    "# Instantiate this callback class and\n",
    "# call the on_epoch_end method to see what it does"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e482d6b8-81b0-4b26-8f38-43a75bbfc199",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcf2447-fcc9-4011-bffd-e96eb3e8b178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap to GPU runtime\n",
    "# Run all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8d9a31",
   "metadata": {
    "id": "2e201123"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    datasets[\"training\"],\n",
    "    epochs=50,\n",
    "    validation_data=datasets[\"validation\"],\n",
    "    callbacks=[DisplayCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b855ca3-7347-48ff-8110-b04eb075daa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the training results. Sometimes it won't converge.\n",
    "# Can re-initialise the model and re-train in that case.\n",
    "\n",
    "## BREAKOUT ROOMS ##\n",
    "# -- Goal: Catch everyone up, and have everyone be able to train a UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568a167b",
   "metadata": {
    "id": "29c6c140"
   },
   "outputs": [],
   "source": [
    "plt.semilogy(history.history[\"loss\"], label=\"Training loss\")\n",
    "plt.semilogy(\n",
    "    history.history[\"val_loss\"],\n",
    "    label=\"Validation loss\",\n",
    ")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "U-Net Workshop",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
