{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4c90de4",
   "metadata": {},
   "source": [
    "# U-Net Workshop\n",
    "\n",
    "Here is an example U-Net implementation using minified data based upon creative commons dataset available at https://wiki.cancerimagingarchive.net/display/Public/HNSCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8991372b",
   "metadata": {
    "id": "0ebfc39a"
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 Radiotherapy AI Pty Ltd\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f612bc",
   "metadata": {
    "id": "23a0eb9f"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "import shutil\n",
    "import urllib.request\n",
    "\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653200d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "GRID_SIZE = 64\n",
    "\n",
    "COLOURS_AND_LABELS = [\n",
    "    (\"#ff7f0e\", \"left parotid\"),\n",
    "    (\"#2ca02c\", \"right parotid\"),\n",
    "    (\"#d62728\", \"external\"),\n",
    "]\n",
    "NUM_CONTOURS = len(COLOURS_AND_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a298396c",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e87a83",
   "metadata": {
    "id": "138d8a13"
   },
   "outputs": [],
   "source": [
    "zip_url = \"https://github.com/RadiotherapyAI/unet-workshop/releases/download/mini-parotid/mini-parotid.zip\"\n",
    "zip_filepath = \"data.zip\"\n",
    "\n",
    "data_directory = pathlib.Path(\"data\")\n",
    "\n",
    "if not data_directory.exists():\n",
    "    urllib.request.urlretrieve(zip_url, zip_filepath)\n",
    "    shutil.unpack_archive(zip_filepath, data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc93240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the `data_directory` with glob and pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2a3db5",
   "metadata": {},
   "source": [
    "## Build the TensorFlow pipeline and investigate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aac903",
   "metadata": {
    "id": "83dced47"
   },
   "outputs": [],
   "source": [
    "def get_path_pairs(dataset_type):\n",
    "    training_image_paths = list((data_directory / dataset_type).glob(\"*/*.image.png\"))\n",
    "    training_mask_paths = [\n",
    "        path.parent / f\"{path.name.split('.')[0]}.masks.png\"\n",
    "        for path in training_image_paths\n",
    "    ]\n",
    "\n",
    "    path_pairs = [\n",
    "        (str(image), str(mask))\n",
    "        for image, mask in zip(training_image_paths, training_mask_paths)\n",
    "    ]\n",
    "\n",
    "    return sorted(path_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd4bf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def load(path_pair):\n",
    "    image_path = path_pair[0]\n",
    "    masks_path = path_pair[1]\n",
    "    \n",
    "    image_raw = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_image(image_raw, channels=1, dtype=tf.uint8)\n",
    "\n",
    "    masks_raw = tf.io.read_file(masks_path)\n",
    "    masks = tf.io.decode_image(masks_raw, channels=3, dtype=tf.uint8)\n",
    "\n",
    "    return image / 255, masks / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210d4999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(dataset_type):\n",
    "    path_pairs = get_path_pairs(dataset_type)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(path_pairs)\n",
    "    dataset = dataset.shuffle(len(path_pairs), reshuffle_each_iteration=True)\n",
    "    dataset = dataset.map(load)\n",
    "\n",
    "    batched_dataset = dataset.batch(BATCH_SIZE)\n",
    "    batched_dataset = batched_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset, batched_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `create_datasets` function to create a set of training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e67f88",
   "metadata": {
    "id": "b23e5637"
   },
   "outputs": [],
   "source": [
    "# Extract an image and masks out of the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c18d88",
   "metadata": {
    "id": "caeb3c4d"
   },
   "outputs": [],
   "source": [
    "# Use matplotlib to investigate the extracted image and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4571f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contours(ax, image, masks):\n",
    "    ax.imshow(image[:, :, 0], cmap=\"gray\")\n",
    "\n",
    "    for i, (colour, label) in enumerate(COLOURS_AND_LABELS):\n",
    "        c = ax.contour(masks[..., i], colors=[colour], levels=[0.5])\n",
    "        c.collections[0].set_label(label)\n",
    "\n",
    "    ax.axis(\"equal\")\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06f3dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `plot_contours` function to view the masks as contours on the ct image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0416bbf8",
   "metadata": {},
   "source": [
    "## Create the 2D U-Net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eb1e85",
   "metadata": {
    "id": "b8427c75"
   },
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def convolution(x, number_of_filters, kernel_size=3):\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        number_of_filters, kernel_size, padding=\"same\", kernel_initializer=\"he_normal\"\n",
    "    )(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_transpose(x, number_of_filters, kernel_size=3):\n",
    "    x = tf.keras.layers.Conv2DTranspose(\n",
    "        number_of_filters,\n",
    "        kernel_size,\n",
    "        strides=2,\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def encode(\n",
    "    x,\n",
    "    number_of_filters,\n",
    "    number_of_convolutions=2,\n",
    "):\n",
    "    for _ in range(number_of_convolutions):\n",
    "        x = convolution(x, number_of_filters)\n",
    "        x = activation(x)\n",
    "    skip = x\n",
    "\n",
    "    x = tf.keras.layers.MaxPool2D()(x)\n",
    "    x = activation(x)\n",
    "\n",
    "    return x, skip\n",
    "\n",
    "\n",
    "def decode(\n",
    "    x,\n",
    "    skip,\n",
    "    number_of_filters,\n",
    "    number_of_convolutions=2,\n",
    "):\n",
    "    x = conv_transpose(x, number_of_filters)\n",
    "    x = activation(x)\n",
    "\n",
    "    x = tf.keras.layers.concatenate([skip, x], axis=-1)\n",
    "\n",
    "    for _ in range(number_of_convolutions):\n",
    "        x = convolution(x, number_of_filters)\n",
    "        x = activation(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0736177d",
   "metadata": {
    "id": "f23747a8"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input((GRID_SIZE, GRID_SIZE, 1))\n",
    "\n",
    "x = inputs\n",
    "skips = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8790dbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the encoding layers and collect the skips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b516218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the decoding layers with skips included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c433cb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Conv2D(\n",
    "    NUM_CONTOURS,\n",
    "    1,\n",
    "    activation=\"sigmoid\",\n",
    "    padding=\"same\",\n",
    "    kernel_initializer=\"he_normal\",\n",
    ")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27987cfa",
   "metadata": {
    "id": "38f49ce5"
   },
   "outputs": [],
   "source": [
    "# Display a summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d4d866",
   "metadata": {
    "id": "dd577efa"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "        tf.keras.metrics.Precision(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d2ff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the newly created model to create a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85aa20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_prediction(image, masks, pred_masks):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6), ncols=2)\n",
    "    plot_contours(ax[0], image, masks)\n",
    "    plot_contours(ax[1], image, pred_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d047a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `plot_with_prediction` function to plot the prediction result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f5cd56",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Now that we've set up our data pipeline, and structured our model, let's train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2673fd67",
   "metadata": {
    "id": "fad0871e"
   },
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        pred_masks = model.predict(image[None, ...])[0, ...]\n",
    "        plot_with_prediction(image, masks, pred_masks)\n",
    "\n",
    "        plt.show()\n",
    "        print(\"\\nSample Prediction after epoch {}\\n\".format(epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac46179",
   "metadata": {
    "id": "2e201123"
   },
   "outputs": [],
   "source": [
    "# Use `model.fit` to run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bd9840",
   "metadata": {
    "id": "29c6c140"
   },
   "outputs": [],
   "source": [
    "# Plot the history of the training and validation loss"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "U-Net Workshop",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
